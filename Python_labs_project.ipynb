{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2729131c",
   "metadata": {
    "tags": [
     "Project_plan"
    ]
   },
   "source": [
    "Project plan\n",
    "\n",
    "1. problem formulation :  \n",
    "Context : we have been instructed to predict books ratings via a machine learning application from provided data.  \n",
    "2. Data preprocessing\n",
    "3. EDA\n",
    "4. features engineering \n",
    "5. modelling & Machine learning \n",
    "6. Model validation\n",
    "7. deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6b1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ab7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate environment \n",
    "#!conda init bash\n",
    "#!conda activate Project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b6ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002c5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib as plt\n",
    "#import plotly as ply\n",
    "import sklearn as skl\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0058b45",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "df = pd.read_csv(\"books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0df230",
   "metadata": {},
   "source": [
    "2 Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da0d13",
   "metadata": {},
   "source": [
    "2.1  inspect data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54080887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3eb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df shape \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f74529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91609d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe numeric variables\n",
    "df.describe(exclude=\"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0043404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe non-numeric  variables\n",
    "df.describe(include=\"object\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38cba68",
   "metadata": {},
   "source": [
    "There is no duplicate ID in data as isbn is 11127 the datat set number of cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128da2a",
   "metadata": {},
   "source": [
    "2.2  clean data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261187e",
   "metadata": {},
   "source": [
    "2.2.1 Clean publication date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change from string to datetime object \n",
    "# for loop to parse date \n",
    "df[\"publication_Date\"]= pd.Series(dtype=\"int\")\n",
    "cnt = 0\n",
    "for i in range(len(df.publication_date)) :\n",
    "    month,day,year = map(int,df.publication_date[i].split('/'))\n",
    "\n",
    "    if month in [4,6,9,11] and day > 30:\n",
    "        day = 30\n",
    "        df[\"publication_Date\"][i] = dt.date(year,month,day)\n",
    "    elif(month==2 and day > 28 and year % 4 != 0):\n",
    "        day = 28\n",
    "    df[\"publication_Date\"][i] = dt.date(year,month,day)\n",
    "    cnt +=1\n",
    "if (cnt == len(df.publication_date)) :\n",
    "    print(\"no date issue\" )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c763a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove heading whitespace from num_pages feature \n",
    "df = df.rename(columns = {\"  num_pages\" : \"num_pages\"})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb646068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#na check in the entire dataset \n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17ae46",
   "metadata": {},
   "source": [
    "There is no NA in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na check in average_rating\n",
    "if (df.average_rating.isna().mean() == 0 ) :\n",
    "    print(\"There is no NA in average_rating\")\n",
    "else:\n",
    "    print(\"There are NA in average_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808cc77",
   "metadata": {},
   "source": [
    "3 EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf210f",
   "metadata": {},
   "source": [
    "1D EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b0bcb",
   "metadata": {},
   "source": [
    "3.1 Numerical summary and 1D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical summary : average_rating \n",
    "df.average_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average ratings \n",
    "df.average_rating.hist(bins=60,legend={\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fe9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average ratings :range [0,3.9]\n",
    "df.average_rating.hist(bins=60,range = [0,3],legend={\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a247bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average ratings :range [0,4.75]\n",
    "df.average_rating.hist(bins=30,range = [3,4.75],legend={\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8159b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average ratings :range [0,3.9]\n",
    "df.average_rating.hist(bins=30,range = [4.75,5],legend={\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cases where averating are <= 3\n",
    "df.loc[df.average_rating <= 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cases where average rating >= 4.75 \n",
    "df.loc[df.average_rating > 4.75].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average ratings sumary statistics \n",
    "df.average_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc497d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average_rating 1st and 3rd quantile \n",
    "IQR_average_rating = df.quantile([0.25,0.75])[[\"average_rating\"]]\n",
    "IQR_average_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76473b7b",
   "metadata": {},
   "source": [
    "average_ratings is almost an unimodal distribution with some outliers.\n",
    "it has median 3.96 and IQR : 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical summary num_pages\n",
    "df.num_pages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of num_pages \n",
    "df.num_pages.hist(bins = 60,legend={\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aef50c",
   "metadata": {},
   "source": [
    "Num_pages is almost an unimodal distribution, right skewed showing that  at least 50% of books presents 299 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical summary ratings_count \n",
    "(df.ratings_count\n",
    ".quantile([0.25,0.5,0.75, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77d5b2",
   "metadata": {},
   "source": [
    "Maximum rating count is so high that it seems suspect !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9129cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# histogram of ratings_count \n",
    "df.ratings_count.hist(bins = 50,range = [0,2000],legend ={\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8750e",
   "metadata": {},
   "source": [
    "Ratings count distribution is unimodal, right skewed. At least 50% of books ratings count is greater or equal to 745."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1084fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical summary publication Date\n",
    "df.publication_Date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1105419",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "[\"publication_Date\"]\n",
    ".quantile([0.0,0.25,0.5,0.75,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c09838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of publication date \n",
    "df.publication_Date.hist(bins = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49a73e",
   "metadata": {},
   "source": [
    "publication date distribution is unimodal and left skewed. At least 50% of books has been published before between 1998 and 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fb1ad",
   "metadata": {},
   "source": [
    "How many books are written in english ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language code \n",
    "df3 = df.groupby(\"language_code\").count()\n",
    "# round \n",
    "round(df3.bookID.filter(regex =\"^[Ee][Nn][g\\\\-]\")/df.shape[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b5734",
   "metadata": {},
   "source": [
    "95% of book are written in English. The english type being diffrent.  \n",
    "It may be reasonble to turn language code into a binary variable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9b1b5",
   "metadata": {},
   "source": [
    "Who are the five most prolific authors ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors\n",
    "(df.groupby(\"authors\")\n",
    " .count()\n",
    " .sort_values(\"title\",ascending=False)\n",
    " [[\"title\"]]\n",
    " .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ce2b7",
   "metadata": {},
   "source": [
    "5 more prolific authors are :  \n",
    "1. S. king\n",
    "2. P.G. Wodehouse\n",
    "3. Rumiko Takahashi\n",
    "4. Orson Scott Card\n",
    "5. Agatha Christie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104cb125",
   "metadata": {},
   "source": [
    "Who are the 5 more prolific publisher ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(\"publisher\")\n",
    " .count()\n",
    " .sort_values(\"title\",ascending=False)\n",
    " [[\"title\"]]\n",
    " .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37612350",
   "metadata": {},
   "source": [
    "The 5 more productive publisher are :   \n",
    "1. Vintage\n",
    "2. Penguin Books \n",
    "3. Penguin Classics\n",
    "4. Mariner Books\n",
    "5. Ballantine Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38750251",
   "metadata": {},
   "source": [
    "What are the first 5 well rated titles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ec4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(\"title\")\n",
    " .agg(\"mean\")\n",
    " .sort_values(by =\"average_rating\",ascending=False)\n",
    " [[\"average_rating\"]]\n",
    " .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab72b9",
   "metadata": {},
   "source": [
    "Above are the 5 well rated books title in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac548d06",
   "metadata": {},
   "source": [
    "We are not going to do EDA on bookID, isbn , isbn13. \n",
    "The first 3 are identifier and have no variation, though it won't bring enough information to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c84ae8",
   "metadata": {},
   "source": [
    "Turn language code into a binary variable and perform EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fa32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin language code  eng : 1 , other : 0\n",
    "language_code_bin = []\n",
    "for i in range(len(df.language_code)) :\n",
    "    if re.match(\"^([Ee][Nn].+)\",df.language_code[i]):\n",
    "        language_code_bin.append(1)\n",
    "    else:\n",
    "        language_code_bin.append(0) \n",
    "df[\"language_code_bin\"]  = language_code_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995db1ae",
   "metadata": {},
   "source": [
    "What is the proportion of books written in English la?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of english in language code. \n",
    "(df.groupby(\"language_code_bin\")\n",
    " .count()/len(df.language_code_bin)\n",
    " ).round(3)[[\"title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9365265",
   "metadata": {},
   "source": [
    "English language has a proportion of 0.95 in language code. 95% of our books are written in English. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb7ed4",
   "metadata": {},
   "source": [
    "== Finding relations between variables ==  \n",
    " 3.2 Numerical summary and  2D plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df771ff7",
   "metadata": {},
   "source": [
    "Is there any association between number of pages and average rating ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73705dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot average rating vs num_pages\n",
    "df.plot.scatter(x=\"num_pages\",y = \"average_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c2a4b",
   "metadata": {
    "tags": [
     "correlation_coef"
    ]
   },
   "outputs": [],
   "source": [
    "# correlation cofficient between average rating and num_pages\n",
    "round(df.average_rating.corr(df.num_pages),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb555e6",
   "metadata": {
    "tags": [
     "summary"
    ]
   },
   "source": [
    "The correlation coeffication is 0.15. This suggest a weak association between \n",
    "average rating and number of pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324b724",
   "metadata": {
    "tags": [
     "2D_plot"
    ]
   },
   "outputs": [],
   "source": [
    "# scatter plot average_rating vs text_reviews_count \n",
    "df.plot.scatter(x=\"text_reviews_count\",y = \"average_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e9669",
   "metadata": {},
   "source": [
    "There is not a clear pattern between these 2 variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd7701",
   "metadata": {
    "tags": [
     "corr_coef"
    ]
   },
   "outputs": [],
   "source": [
    "# correlation coef\n",
    "round(df.average_rating.corr(df.text_reviews_count),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478d004",
   "metadata": {},
   "source": [
    "The correlation coef is almost 0. This suggest no association between average rating and text reviews count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot average rating. vs ratings count \n",
    "df.plot.scatter(x=\"ratings_count\",y = \"average_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation coeff between average rating and ratings count \n",
    "round(df.average_rating.corr(df.ratings_count),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24256a43",
   "metadata": {},
   "source": [
    "The correlation coefficient between average rating and ratings count is 0.04. This suggest that there is almost no association between average rating and rating count. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d91f8d",
   "metadata": {},
   "source": [
    "what is the average rating of books written in english ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(\"language_code_bin\")\n",
    " .agg(\"mean\")\n",
    "[[\"average_rating\"]]\n",
    ".round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580bde4",
   "metadata": {},
   "source": [
    "On average,books written in English are less well rated than books written in other languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932af2d",
   "metadata": {},
   "source": [
    "=== 2D EDA SUMMARY ===    \n",
    "-numerical features are not strongly associated with average rating if considering a linear assosiation. In a linear modeling numerical features have no effect or a little one on average rating. Let's investigate other models i.e. tree based model or svm. \n",
    "\n",
    "Qualitative variable,i.e. language_code has on average a rating of 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476ebae",
   "metadata": {},
   "source": [
    "4 === features engineering part1  ===  \n",
    "we are going to remove bookID, title , authors,isbn,isbn13, publisher because they have presents no variation and are less informative for our application.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c860b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe : df1 and remove some features \n",
    "df1 = df[['bookID','title','authors','isbn','isbn13',\n",
    "               'publisher']]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.average_rating.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da42a77",
   "metadata": {},
   "source": [
    "4.1 Discretize average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize average rating \n",
    "av_cat = []\n",
    "av_cat = pd.cut(df.average_rating,bins=[0,1,2,3,4,5,6],\n",
    "                    labels = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"],\n",
    "                    include_lowest=True)\n",
    "df1[\"av_cat\"] = av_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head average rating \n",
    "df1.av_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26460dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail av rating \n",
    "df1.av_cat.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of classes in the data \n",
    "round(df1.av_cat.value_counts()/ len(df1.av_cat),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce0e44",
   "metadata": {},
   "source": [
    "There is 40% of data in class 4 and 56% in class 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d582e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.av_cat.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf208c",
   "metadata": {},
   "source": [
    "Discretizing average_rating  make it unbalanced data.  \n",
    "We need to fix unbalalced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4da1fd",
   "metadata": {},
   "source": [
    "======== REGRESSION ======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bdbee6",
   "metadata": {},
   "source": [
    "4.2 Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e297e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting numerical features\n",
    "df1 = df[['average_rating', 'num_pages', \n",
    "          \"language_code_bin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f997bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.average_rating.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df922f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train0,test = train_test_split(df1, test_size= 20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8467d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train0 in train and valid \n",
    "train,valid = train_test_split(train0,test_size=40,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting \n",
    "# train0\n",
    "X_train0 = train0.drop(\"average_rating\",axis = 1)\n",
    "y_train0 = train0.average_rating\n",
    "\n",
    "# train\n",
    "X_train = train.drop(\"average_rating\",axis = 1)\n",
    "y_train = train.average_rating\n",
    "\n",
    "# valid \n",
    "X_valid = valid.drop(\"average_rating\",axis=1)\n",
    "y_valid = valid.average_rating\n",
    "\n",
    "# test \n",
    "X_test = test.drop(\"average_rating\",axis = 1)\n",
    "y_test = test.average_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b32b14",
   "metadata": {},
   "source": [
    "5 modelling : model testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a64e83",
   "metadata": {},
   "source": [
    "5.1 Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753dc5c",
   "metadata": {},
   "source": [
    "-linear model : OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aefb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model \n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bcac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats model package\n",
    "X = sm.add_constant(X_train)\n",
    "mdl = sm.OLS(y_train,X_train)\n",
    "fit = mdl.fit()\n",
    "# print model \n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d80349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-statistics an p-value \n",
    "sm.stats.linear_rainbow(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342c7a1",
   "metadata": {},
   "source": [
    "-regularized linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2792b",
   "metadata": {},
   "source": [
    "-Ridge : alpha = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e71c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularized model : ridge model, alpha = 0.1 \n",
    "reg_ridge = linear_model.Ridge(alpha=0.01)\n",
    "reg_ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf05111",
   "metadata": {},
   "source": [
    "-ridge alphas, cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge model with cross validation \n",
    "# regularized model : ridge model with cv =5\n",
    "reg_ridge_CV = linear_model.RidgeCV(alphas=[0.001,0.01,0.1,1,10],cv=5)\n",
    "reg_ridge_CV.fit(X_train0,y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921b419",
   "metadata": {},
   "source": [
    "-Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e11c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import linear_model, alpha = 0.5\n",
    "reg_lasso = linear_model.Lasso(alpha=0.5)\n",
    "reg_lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe850d2",
   "metadata": {},
   "source": [
    "5.2 Tree based model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c69f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree based model \n",
    "from sklearn import tree\n",
    "regressor = tree.DecisionTreeRegressor(random_state=40)\n",
    "tree_reg= regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487847d",
   "metadata": {},
   "source": [
    "5.3 Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " #random forest\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "rf = RandomForestRegressor(n_estimators= 100,\n",
    "#max_depth = 5,\n",
    "random_state=42)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f25fae",
   "metadata": {
    "tags": [
     "generalised_boosting_machine"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8671773",
   "metadata": {},
   "source": [
    "5.4 Support vectors machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear svm\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, random_state=0)\n",
    "svm_regr = make_pipeline(StandardScaler(),\n",
    "                     LinearSVR(random_state=0, tol=1e-5,max_iter=100000))\n",
    "svm_regr.fit(X, y)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf098e",
   "metadata": {},
   "source": [
    "5.5 MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross val custom function \n",
    "def model_cross_val(models={}, X_validation=None,y_validation= None,cv=None, scoring = \"neg_mean_squared_error\"):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    table = []\n",
    "    for mod in models :\n",
    "        score = abs(\n",
    "            cross_val_score(models[mod],\n",
    "                            X_validation,\n",
    "                            y_validation,\n",
    "                            cv=cv,\n",
    "                            scoring=scoring ).mean()\n",
    "        )\n",
    "        table.append(abs(score))\n",
    "    print(\n",
    "         pd.DataFrame(data = table,index = models,columns = [\"rmse\"])\n",
    "        .sort_values(by =\"rmse\")\n",
    "        \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395fcd2",
   "metadata": {},
   "source": [
    " Models performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to cross-validate \n",
    "\n",
    "# models to cross validate\n",
    "models = {\"linear reg\": reg,\n",
    "          \"ridge model\":reg_ridge,\n",
    "          \"lasso model \": reg_lasso,\n",
    "          \"ridge CV\":reg_ridge_CV,\n",
    "          \"random forest\":rf,\n",
    "          \"linear svm\":svm_regr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2588bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation  \n",
    "model_cross_val(models,X_valid,y_valid,cv= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda1ce7",
   "metadata": {},
   "source": [
    "=== The candidates model are randomForest and Linear svm. === "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b87aa",
   "metadata": {},
   "source": [
    "What is outliers effect on models ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82389f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# remove outliers from a erage rating only\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39maverage_rating \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_rating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_pages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_reviews_count\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove outliers from a erage rating only\n",
    "df2 = df.loc[df.average_rating >= 2,['average_rating', 'num_pages', 'ratings_count', 'text_reviews_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a694e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b609fd2",
   "metadata": {},
   "source": [
    "Here , we keep ratings_count and text_reviews_count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f140ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and remove outliers function\n",
    "def remove_outliers(X,bins = 50, plot = \"bool\"):\n",
    "    # q1 and q3 quantiles\n",
    "    q1,q3 = X.quantile([0.25,0.75])\n",
    "    #print(q1,q3)\n",
    "\n",
    "    #interquatile range \n",
    "    iqr = q3 - q1\n",
    "    #print(pd.DataFrame([[q1, q3 ,iqr]],columns = [\"q1\",\"q3\",\"IQR\"]))\n",
    "\n",
    "    # remove \n",
    "    if q1 - 1.5*iqr < 0 :\n",
    "          X =  X[X.between(q1 - 1.5*iqr, q3 + 1.5*iqr,inclusive = \"both\")]\n",
    "       \n",
    "    else:\n",
    "          X = X[X.between(q1 - 1.5*iqr, q3 + 1.5*iqr,inclusive = \"both\")]\n",
    "    # histogram\n",
    "    if plot :\n",
    "          X.hist( bins = bins,legend = {\"\"})\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f3d73e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241m.\u001b[39maverage_rating\u001b[38;5;241m.\u001b[39mhist(bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.average_rating.hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_outliers(df.average_rating, bins = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from num_pages\n",
    "remove_outliers(df1.num_pages,bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bac2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train,test = train_test_split(df2, test_size= 0.4,random_state=42)\n",
    "\n",
    "# train\n",
    "X_train = train.drop(\"average_rating\",axis=1)\n",
    "y_train = train.average_rating\n",
    "\n",
    "# test\n",
    "X_test = test.drop(\"average_rating\",axis=1)\n",
    "y_test = test.average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model \n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats model package\n",
    "X = sm.add_constant(X_train)\n",
    "mdl = sm.OLS(y_train,X_train)\n",
    "fit = mdl.fit()\n",
    "# print model \n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd933a0",
   "metadata": {},
   "source": [
    "!!! Without outliers, we do not have multicollinearity in data in the above summary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1338305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "reg_lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48740eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge\n",
    "reg_ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbab8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "svm_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3975969",
   "metadata": {},
   "source": [
    "7 Models new evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ca536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cross_val(models,X_validation=X_test, y_validation=y_test, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613040f",
   "metadata": {},
   "source": [
    "== Regression application : conclusion  === \n",
    "* The models performance is better without outliers.  \n",
    "* Linear models are better than non-linear ones. \n",
    "* The candidate models could be  Lasso and ridge with CV, i.e. Regularized linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80c907",
   "metadata": {},
   "source": [
    "=== Categrical application === "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f02838",
   "metadata": {},
   "source": [
    "\n",
    "end of  file "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f400fd3917260b4df2a70e64dd1b6b0f213226eb51aa2d986fb9f86518ca676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
